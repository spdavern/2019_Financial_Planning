---
title: "Transferring 2013 Analysis to R"
author: "Sean Davern"
date: "June 5, 2019"
output:
  html_document:
    df_print: paged
  pdf_document: default
  html_notebook: default
references:
- id: davern2013
  title: An Assessment of Requested Seed Core Support for Expansion Based on Analysis of Giving
  author:
  - family: Davern
    given: Sean
  container-title: Internal Report
  URL: "file://../Reports/August%202013%20Analysis%20of%20Giving.pdf"
  DOI: 
  type: article-journal
  issued:
    year: 2013
    month: 8
    day: 21
---
# Objective of this Work
The objective of the work captured in this notebook is to translate part of an analysis done in 2013 (See @davern2013) into R to learn and demonstrate multiple R capabilities and workflows.

# Import of Data
The original data was provided by John Earling in a work book entitled 'Weekly PayPay & Tithes .xls' workbook.  The layout/format of that workbook was not conducive to easily loading into R [nor JMP originally] and so was transcribed into the workbook 'Giving Data.xlsx' and then read into R.

```{r extract, message=FALSE}
source("../code/0-Extract data from Excel.R")
df  # This is the data frame resulting from the import.
```
# Some Minor Data Validation
As a first validation I'll check that the weekly PayPal and offering amounts sum to the weekly totals $(paypal_i+{offering}_i\overset{?}=total_i)$, reporting only those that aren't equal:
```{r validate totals}
source("../code/1-Validate totals.R")
```
Ok, so December 2015 and 2016 seem to have totals greater than accounted for by the PayPal and offering amounts.  That's perhaps explainable by other end-of-year giving coming in another way.  However, the April 2017 discrepancy seems to be missing $500.  I'll need to look into that.

# Data Transformation

Aggregating the monthly totals and preparing to model month values...
```{r}
# Data transformation: Calculate monthly giving totals.
# Make Month a categorical variable with levels in the order that
# months occur in the year otherwise months are sorted alphabetically.
df$month <- factor(df$month, month.name)
# Aggregate the monthly Totals from giving.data in sums for each month.
MonthTotals <- 
  aggregate(df$total, by = list(df$month, df$year), FUN = sum)
# Exclude the months that don't have totals yet.
MonthTotals <- MonthTotals[complete.cases(MonthTotals), ]
# Extract only rows containing 'monthly.giving.families' data.
df <- df[!is.na(df$monthly.giving.families),]
# Now replace Totals (which were weekly totals) with calculated aggregates
df$total <- MonthTotals$x
# paypal & offering columns are now misleading (only week's value) so remove them.
df <- select(df, -paypal, -offering) 
```
Adding the number of giving Sundays in the month and the average giving each week per month...
```{r}
library("magrittr")
source("../code/NumOfGivenDayOfWeekInMonth.R")
# Calculate and add the columns SundaysInMonth with calculated values
# and MonthsGivingPerWeek
df <-  df %>%
  mutate(SundaysInMonth =
           NumOfGivenDayOfWeekInMonth(df$week.ending, "Sunday")) %>%
  mutate(MonthsGivingPerWeek = total / SundaysInMonth)
```
Enable modeling year as factor rather than a number...
```{r}
# Make year a categorical variable so coefficients are easier to interpret.
df$year <- as.factor(df$year)
```
Save the resulting R tibble:
```{r echo=TRUE, eval=FALSE}  
# Code chunk eval=false so files don't get overwritten willy nilly.
# Write it as a csv:
write.csv(x = df,
          file = "../data/Cleaned and Transformed Giving Data.csv",
          row.names = FALSE)
# Save it also as an R object that can be loaded into a new R object.
saveRDS(df, file = "../data/Cleaned and Transformed Giving Data.rds")
```

\newpage
# Replicating Previous Modeling
The relatively simple model derived in 2013 [see @davern2013, pg. 11] and used again in 2018 used this model:
$$\text{Monthly Giving} = a_1+b_{year}+c_{month}$$
where $a_1$ is an overall grand average of the monthly giving amount, $b_{year}$ is an adjustment for the given year and $c_{month}$ is an adjustment for the month. The model was originally regressed on giving data from Jan 2010 through August 2013 excluding 3 high-fliers with known exceptional donations.
We can now regress this model:

```{r}
library("magrittr")
# Pair the data down to that used in the original analysis
df2 <- df[as.Date(df$week.ending) > "2010-01-01" & 
            as.Date(df$week.ending) < "2013-08-31",] %>%
  mutate(excluded = FALSE)
df2$excluded[as.Date(df2$week.ending) == "2010-02-28"] <- TRUE
df2$excluded[as.Date(df2$week.ending) == "2012-04-29"] <- TRUE
df2$excluded[as.Date(df2$week.ending) == "2012-12-30"] <- TRUE
# Regress the model cluding the indicated values:
mod <- lm(
  formula = total ~
    year + month,
  data = df2[df2$excluded!=TRUE,]
)
```

Which gives the resulting model fit:

```{r echo=FALSE, message=FALSE}
library("magrittr")
library("ggplot2")
library("RColorBrewer")
cbPalette <- brewer.pal(12,"Paired")  # Used http://colorbrewer2.org/
names(cbPalette) <- levels(month.name)
colScale <- scale_color_manual(name = "month", values = cbPalette)
# For plots showing excluded points comment out this next line:
#df3 <- df2[df2$excluded!=TRUE,]
df3 <- df2
df3 <- mutate(df3, predicted.values = predict(mod,df3)) %>%
  mutate(residual.values = total - predicted.values )
t.size <- 9
ggplot(df3, aes(x = week.ending, y = total, color=month )) +
  geom_point() + geom_line(color='blue', 
                           data = df3, 
                           aes(x=week.ending,y=predicted.values)) +
  colScale + labs(title = "Monthly Giving Model & Data") + 
  theme(text = element_text(size=t.size),
        panel.grid.major = element_line(color = "azure2",
                                        linetype = "dashed",
                                        line)) +
  scale_y_continuous(breaks = seq(10000, 26000, by=2000),
                     labels = scales::comma) +
  labs(x = "Date", y = "Month's Total Giving ($)")
```

Note: excluded points [high fliers] are shown (above and below) though they weren't included in the regression.  Here are the fit diagnostics:

```{r echo=FALSE, message=FALSE}
library("gridExtra")
# library("cowplot")
anova(mod)
plot1 <- ggplot(mod, aes(sample = mod$residuals)) +
  stat_qq() + 
  stat_qq_line(linetype="dashed", color="blue") +
  labs(x = "Theoretical Quantiles",
       y = "Standardized Residuals",
       title = "Normal Q-Q Plot") +
  theme(text = element_text(size=t.size))
plot2 <- ggplot(df3, aes(x = predicted.values, y = total, color=month)) + 
  geom_point() + geom_abline(intercept = 0, slope = 1, color="red") +
  colScale + labs(x = "Monthly Giving Predicted", 
                  y = "Monthly Giving Actual",
                  title = "Act. by Pred. Plot") +
  theme(text = element_text(size=t.size), 
        axis.text.x = element_text(angle=45, hjust=1)) +
  theme(legend.position="none")
plot3 <- ggplot(df3, aes(x = predicted.values, y = residual.values, color = month)) +
  geom_point() + geom_hline(yintercept = 0, linetype="dashed", 
                            color = "blue") +
  colScale + labs(x = "Monthly Giving Predicted", y = "Residuals",
                  title = "Resid. by Pred. Plot") + 
  theme(text = element_text(size=t.size), 
        axis.text.x = element_text(angle=45, hjust=1)) +
  theme(legend.position="none")
plot4 <- ggplot(df3, aes(x = as.numeric(row.names(df3)), 
                         y = residual.values, 
                         color = month)) + 
  geom_point() + geom_hline(yintercept = 0, 
                            linetype="dashed", 
                            color = "blue") + 
  colScale +
  labs(x = "Row Number", 
       y = "Residuals",
       title = "Resid. by Row Plot") + 
  theme(text = element_text(size=t.size)) +
  theme(legend.position="none")
grid.arrange(plot2, plot3, plot4, plot1, ncol=2, nrow=2)
# plot_grid(plot2, plot3, plot4, labels = "AUTO")
summary(mod)
```
The results obtained are different in a number of ways from what was obtained in 2013.  The general fit (residuals) and shape of the predicted values are similar to that obtained in 2013 though the June predictions seem further away than the other months.  The regressed coefficients are obviously very different, but this is largely due to the method JMP uses for regressing factor coefficients.  However, the difference in the June predictions and slightly different factor p-values tells me that something in the underlying data is probably different.  I'm not going to spend the time to diagnose the precise details of the difference since the objective is to translate the analysis to R rather than reproduce it. 


# References